# Ultralytics YOLO ğŸš€, AGPL-3.0 license
"""
MR_HCSA (é€’å½’å²©çŸ³çº¹ç†å¢å¼ºç‰ˆHCSA)
ç»“åˆé€’å½’é€šé“æ³¨æ„åŠ›å’Œè½»é‡çº§å²©çŸ³çº¹ç†ç¼–ç 
"""

import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from ultralytics.nn.modules.conv import Conv

def channel_shuffle(x, groups=2):
    """Channel shuffle operation for mixing information across groups."""
    B, C, H, W = x.size()
    out = x.view(B, groups, C // groups, H, W).permute(0, 2, 1, 3, 4).contiguous()
    out = out.view(B, C, H, W)
    return out

class LightweightTextureEnhancer(nn.Module):
    """è¶…è½»é‡çº§å²©çŸ³çº¹ç†å¢å¼ºå™¨"""
    def __init__(self, channels):
        super().__init__()
        # ä½¿ç”¨æ·±åº¦å¯åˆ†ç¦»å·ç§¯æå¤§å‡å°‘è®¡ç®—é‡
        self.depthwise = nn.Conv2d(
            channels, channels, kernel_size=3, padding=2, dilation=2, 
            groups=channels, bias=False  # æ¯ä¸ªé€šé“å•ç‹¬å·ç§¯
        )
        self.pointwise = nn.Conv2d(
            channels, channels, kernel_size=1, bias=False
        )
        self.activate = nn.SiLU(inplace=True)
        
        # å¯å­¦ä¹ ç¼©æ”¾å› å­
        self.gamma = nn.Parameter(torch.zeros(1))
        
    def forward(self, x):
        # æ·±åº¦å¯åˆ†ç¦»å·ç§¯
        texture = self.depthwise(x)
        texture = self.pointwise(texture)
        texture = self.activate(texture)
        
        # æ®‹å·®è¿æ¥ + å¯å­¦ä¹ ç¼©æ”¾
        return x + self.gamma * texture

class RecursiveChannelAttention(nn.Module):
    """é€’å½’é€šé“æ³¨æ„åŠ› - åœ¨å•æ¨¡å—å†…æ¨¡æ‹Ÿå¤šå±‚å †å æ•ˆæœ"""
    def __init__(self, channels, reduced_channels, recursion_depth=3):
        super().__init__()
        self.recursion_depth = recursion_depth
        
        # å…¨å±€æ± åŒ–
        self.pool = nn.AdaptiveAvgPool2d(1)
        
        # é€šé“é™ç»´
        self.down = nn.Sequential(
            nn.Linear(channels, reduced_channels),
            nn.LayerNorm(reduced_channels),
            nn.SiLU(inplace=True)
        )
        
        # é€’å½’å¤„ç†å•å…ƒ
        self.recursive_layers = nn.ModuleList([
            nn.Sequential(
                nn.Linear(reduced_channels, reduced_channels),
                nn.LayerNorm(reduced_channels),
                nn.SiLU(inplace=True)
            ) for _ in range(recursion_depth)
        ])
        
        # é€šé“å‡ç»´
        self.up = nn.Linear(reduced_channels, channels)
        self.sigmoid = nn.Sigmoid()
        
        # é€’å½’æ­¥æ•°çš„æƒé‡
        self.recursive_weights = nn.Parameter(torch.ones(recursion_depth + 1))
        
    def forward(self, x):
        b, c = x.shape[0], x.shape[1]
        
        # åˆå§‹ç‰¹å¾
        feat = self.down(self.pool(x).flatten(1))
        
        # ä¿å­˜æ‰€æœ‰é€’å½’æ­¥éª¤çš„ç»“æœ
        recursive_feats = [feat]
        
        # é€’å½’ç»†åŒ–
        for layer in self.recursive_layers:
            feat = layer(feat)
            recursive_feats.append(feat)
        
        # è‡ªé€‚åº”åŠ æƒç»„åˆä¸åŒé€’å½’æ·±åº¦çš„ç‰¹å¾
        weights = F.softmax(self.recursive_weights, dim=0)
        combined = torch.zeros_like(recursive_feats[0])
        for i, feat in enumerate(recursive_feats):
            combined += feat * weights[i]
        
        # ç”Ÿæˆæ³¨æ„åŠ›æƒé‡
        channel_attn = self.sigmoid(self.up(combined)).view(b, c, 1, 1)
        
        return channel_attn


class MR_HCSA(nn.Module):
    """
    é€’å½’å²©çŸ³çº¹ç†å¢å¼ºå‹ HCSA
    
    ç»“åˆé€’å½’é€šé“æ³¨æ„åŠ›å’Œè½»é‡çº§å²©çŸ³çº¹ç†ç¼–ç 
    """
    def __init__(self, c1, c2, reduction=4, num_heads=4, spatial_kernel_sizes=[3, 7], recursion_depth=3):
        super().__init__()
        assert c1 == c2, "è¾“å…¥è¾“å‡ºé€šé“æ•°å¿…é¡»ç›¸åŒä»¥ç»´æŒYOLOv8ç»“æ„"
        
        # è½»é‡çº§å²©çŸ³çº¹ç†å¢å¼ºå™¨ - ç”¨åœ¨æ—©æœŸç‰¹å¾å¢å¼º
        self.texture_enhancer = LightweightTextureEnhancer(c1)
        
        # å‚æ•°å®šä¹‰
        self.branch_channels = c1  # æ¯ä¸ªåˆ†æ”¯çš„é€šé“æ•°
        self.reduced_channels = max(32, c1 // reduction)  # ç¡®ä¿è‡³å°‘æœ‰32ä¸ªé€šé“
        self.num_heads = max(1, min(num_heads, self.reduced_channels // 32))
        
        # è¾“å…¥åˆ†å‰²
        self.split_conv = Conv(c1, c1 * 2, 1)
        
        #===== ç¬¬ä¸€åˆ†æ”¯: GAMè·¯å¾„ =====
        # é€’å½’é€šé“æ³¨æ„åŠ›
        self.channel_attention = RecursiveChannelAttention(
            self.branch_channels, self.reduced_channels, recursion_depth
        )
        
        # æ–¹å‘æ„ŸçŸ¥ç©ºé—´æ³¨æ„åŠ› - ä¿æŒåŸHCSAå®ç°
        self.spatial_h = nn.Conv2d(self.branch_channels, self.branch_channels, 
                                  kernel_size=(1, spatial_kernel_sizes[1]), 
                                  padding=(0, spatial_kernel_sizes[1]//2), 
                                  bias=False)
        self.spatial_v = nn.Conv2d(self.branch_channels, self.branch_channels, 
                                  kernel_size=(spatial_kernel_sizes[1], 1), 
                                  padding=(spatial_kernel_sizes[1]//2, 0), 
                                  bias=False)
        self.spatial_conv = Conv(self.branch_channels * 2, self.branch_channels, spatial_kernel_sizes[0])
        self.spatial_final = nn.Conv2d(self.branch_channels, self.branch_channels, kernel_size=1)
        self.spatial_sigmoid = nn.Sigmoid()
        
        #===== ç¬¬äºŒåˆ†æ”¯: PSAè·¯å¾„ - ä¿æŒåŸHCSAå®ç° =====
        self.qkv = nn.Linear(self.branch_channels, self.branch_channels * 3, bias=False)
        self.attn_drop = nn.Dropout(0.1)
        self.proj = nn.Linear(self.branch_channels, self.branch_channels)
        self.proj_drop = nn.Dropout(0.1)
        
        # ä½ç½®ç¼–ç è®¾ç½® - ä¿æŒä¸åŸHCSAä¸€è‡´
        self.use_pos_embed = False
        
        # FFN - ä¿æŒåŸHCSAå®ç°
        self.ffn1 = Conv(self.branch_channels, self.branch_channels * 2, 1)
        self.ffn2 = Conv(self.branch_channels * 2, self.branch_channels, 1, act=False)
        
        # æµäº¤äº’æ³¨æ„åŠ› - ä¿æŒåŸHCSAå®ç°
        self.cross_conv = Conv(self.branch_channels * 2, 2, 1, act=False)
        self.cross_sigmoid = nn.Sigmoid()
        
        # è¾“å‡ºèåˆ - ä¿æŒåŸHCSAå®ç°
        self.output_conv = Conv(c1 * 2, c2, 1)

    def forward(self, x):
        # å²©çŸ³çº¹ç†å¢å¼º - åœ¨è¾“å…¥é˜¶æ®µåº”ç”¨
        x = self.texture_enhancer(x)
        
        # ç‰¹å¾åˆ†å‰²
        split_features = self.split_conv(x)
        a, b = split_features.chunk(2, dim=1)  # åˆ†æˆä¸¤ä¸ªåˆ†æ”¯ï¼Œæ¯ä¸ªåˆ†æ”¯çš„é€šé“æ•°ä¸ºc1
        
        #===== ç¬¬ä¸€åˆ†æ”¯: GAMè·¯å¾„å¤„ç† =====
        # é€’å½’é€šé“æ³¨æ„åŠ›
        channel_attn = self.channel_attention(b)
        b_channel = b * channel_attn
        
        # æ–¹å‘æ„ŸçŸ¥ç©ºé—´æ³¨æ„åŠ› - ä¸åŸHCSAç›¸åŒ
        spatial_h = self.spatial_h(b_channel)
        spatial_v = self.spatial_v(b_channel)
        spatial_combined = torch.cat([spatial_h, spatial_v], dim=1)
        spatial_conv = self.spatial_conv(spatial_combined)
        spatial_final = self.spatial_final(spatial_conv)
        spatial_attn = self.spatial_sigmoid(spatial_final)
        b_spatial = b_channel * spatial_attn
        
        #===== ç¬¬äºŒåˆ†æ”¯: PSAè·¯å¾„ - å®Œå…¨æŒ‰ç…§åŸHCSAå®ç° =====
        a_shape = a.shape
        a_flat = a.flatten(2).transpose(1, 2)  # [B, HW, C]
        
        # ç”Ÿæˆ q, k, v - ä¸åŸHCSAç›¸åŒ
        qkv = self.qkv(a_flat)  # [B, HW, 3*C]
        qkv = qkv.reshape(a_shape[0], -1, 3, self.num_heads, self.branch_channels // self.num_heads)
        qkv = qkv.permute(2, 0, 3, 1, 4)  # [3, B, num_heads, HW, C//num_heads]
        q, k, v = qkv[0], qkv[1], qkv[2]
        
        # è®¡ç®—æ³¨æ„åŠ› - ä¸åŸHCSAç›¸åŒ
        attn = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))
        
        # ä¸ä½¿ç”¨ä½ç½®ç¼–ç  - ä¸å½“å‰HCSAå®ç°ä¸€è‡´
        attn = attn.softmax(dim=-1)
        attn = self.attn_drop(attn)
        
        # åº”ç”¨æ³¨æ„åŠ› - ä¸åŸHCSAç›¸åŒ
        x_attn = (attn @ v).transpose(1, 2).reshape(a_shape)
        a_attn = x_attn + a  # ç¬¬ä¸€ä¸ªæ®‹å·®è¿æ¥
        
        # FFNå¤„ç† + æ®‹å·®è¿æ¥ - ä¸åŸHCSAç›¸åŒ
        a_ffn = self.ffn2(self.ffn1(a_attn))
        a_out = a_attn + a_ffn  # ç¬¬äºŒä¸ªæ®‹å·®è¿æ¥
        
        #===== æµäº¤äº’å’Œè¾“å‡ºå¤„ç† - ä¸åŸHCSAç›¸åŒ =====
        # æµäº¤äº’æ³¨æ„åŠ›
        combined = torch.cat([a_out, b_spatial], dim=1)
        gates = self.cross_sigmoid(self.cross_conv(combined))
        gate_a, gate_b = gates.chunk(2, dim=1)
        
        # äº¤å‰æ³¨æ„åŠ›åŠ æƒ
        a_cross = a_out * gate_a + b_spatial * (1 - gate_a)  # å°†ç©ºé—´ä¿¡æ¯èå…¥é€šé“æµ
        b_cross = b_spatial * gate_b + a_out * (1 - gate_b)  # å°†é€šé“ä¿¡æ¯èå…¥ç©ºé—´æµ
        
        # ç‰¹å¾èåˆ
        out = torch.cat([a_cross, b_cross], dim=1)
        
        # é€šé“æ··æ´—å¢å¼ºç‰¹å¾äº¤äº’
        out = channel_shuffle(out, groups=4)
        
        # è¾“å‡ºå¤„ç†
        return self.output_conv(out)